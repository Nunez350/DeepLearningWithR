{
    "collab_server" : "",
    "contents" : "rm(list=ls(all=TRUE))\n#single-layer multi neuron classifier\nx<-iris;eta=0.1#the learning rate\nt1<-c(rep(1,50),rep(0,50),rep(0,50));t2<-c(rep(0,50),rep(1,50),rep(0,50));t3<-c(rep(0,50),rep(0,50),rep(1,50))#third target\n\n#generates random weights, initializes weights, random bias and activation\ngneuron<-function(n){\n  w<-runif(4, 1e-3, 1e-2)#random weights\n  #w1=w[1];w2=w[2];w3=w[3];w4=w[4]#initiating weights\n  b<-runif(1)#random bias\n  x1<-iris[,1];x2<-iris[,2]; x3<-iris[,3]; x4<-iris[,4]\n  z=x1*w[1] + x2*w[2] + x3*w[3] + x4*w[4] +b\n  h<-list(z,w,b)\n  return(h)\n}\n\n#list of neurons with activation function\nl.neurons<-lapply(1:3, function(x) gneuron(x));names(l.neurons)<-c(\"z1\",\"z2\",\"z3\")\n\nhistorical.weight<-list();epoch<-NULL\nneuron.upd.weights1<-data.frame();neuron.upd.weights2<-data.frame();neuron.upd.weights3<-data.frame()\nfor (epoch in 1:1000){\n  #apply exponent function to all z\n  z1e<-exp(unlist(l.neurons[[1]][1]));z2e<-exp(unlist(l.neurons[[2]][[1]]));z3e<-exp(unlist(l.neurons[[3]][[1]]))\n  exp.act.list<-list(z1e,z2e,z3e)\n  \n  y1<-unlist(z1e)/(unlist(z1e)+unlist(z2e)+unlist(z3e));y2<-unlist(z2e)/(unlist(z1e)+unlist(z2e)+unlist(z3e));y3<-unlist(z3e)/(unlist(z1e)+unlist(z2e)+unlist(z3e))\n  y=cbind(unlist(y1),unlist(y2),unlist(y3))\n  \n  e1=t1-y[,1]#calculates the error. Difference between the desired and predicted outpute1=t1-y[,1]\n  e2=t2-y[,2]\n  e3=t3-y[,3]\n  e<-cbind(e1,e2,e3)\n  \n  updated.wx<-NULL\n  gc<-NULL\n  delta.w<-NULL\n  n.r<-NULL\n  sum.w<-NULL\n  bias<-NULL\n  delta.bias<-NULL\n  for (n in 1:3){\n    delta.bias[[n]]<-append(bias,(-sum(e[,n])/150))\n    for (c in 1:4){\n      for (r in 1:150){\n        gc<-rbind(gc, x[r,c] * e[r,n])\n      }\n      delta.w[c]<- -sum(gc)  \n      gc<-NULL\n    }\n    n.r[[n]]<-delta.w\n    updated.wx<-NULL\n    sw<-NULL\n    \n    \n  }\n  \n  r.bias<-NULL\n  r.bias<-lapply(l.neurons, function(lx){\n    matrix(unlist(lx[][3]))#nrow=1, ncol=4,byrow=T)\n  })\n\n  r.weights<-NULL\n  r.weights<-lapply(l.neurons, function(lx){\n  matrix(unlist(lx[][2]),nrow=1, ncol=4,byrow=T)\n  \n  })\n  \n\n    nwn<-list()\n   for (n in 1:3){\n     r.bias[[n]]<-cbind(r.bias[[n]],r.bias[[n]]-eta*delta.bias[[n]])\n     \n      temp<-data.frame(r.weights[[n]])\n      for (ew in 1:4) { \n          for (i in 1:1){\n          temp[i+1,ew]<-temp[i,ew]-eta*n.r[[n]][[ew]]\n          }\n        }\n      nwn[[n]]<-temp\n    }\n    nwn\n    r.bias[[1]]\n    r.bias[[2]]\n    r.bias[[3]]\n    \n    neuron.upd.weights1<-rbind(neuron.upd.weights1, nwn[[1]])\n    neuron.upd.weights2<-rbind(neuron.upd.weights2, nwn[[2]])\n    neuron.upd.weights3<-rbind(neuron.upd.weights3, nwn[[3]])\n}\n\nlength(neuron.upd.weights1[,1])\nlength(neuron.upd.weights1[,2])\nneuron.upd.weights1[,1]\nplot(1:2000,neuron.upd.weights1[,1], ylim=c(-200,200), col=\"red\", ylab= \"weights\", xlab=\"Epochs\" )\nlines(1:4000,neuron.upd.weights1[,2], col=\"blue\")\nlines(1:4000,neuron.upd.weights1[,3], col=\"green\")\nlines(1:4000,neuron.upd.weights1[,4], col=\"yellow\")\n\n\nlines(1:10000,neuron.upd.weights2, col=\"blue\")\nlines(1:10000,neuron.upd.weights3, col=\"blue\")\n\n#using weight and bias to predict species \n#r.bias[[1]], r.bias[[2]], r.bias[[3]]\nr.bias\nl.bias<- as.numeric(bias.list[10000])\nfw1<-as.numeric(weights1[10000]); fw2<-as.numeric(weights2[10000])\ny=1/(1+exp(-(fw1*x1 + fw2 * x2 + l.bias)))\nround(y,1)\nweights1[10000]\n#target accuracy at each iteration\nplot(1:10000,tacc)\nls()\n\nstr(nwn)[[]]\nnwn<-data.frame(l.neurons[[1]][[2]],l.neurons[[2]][[2]],l.neurons[[3]][[2]])\ngen<-data.frame()\nfor (g in 1:10){\n  for (n in 1:3){\n    r.bias[[n]]<-cbind(r.bias[[n]],r.bias[[n]]-eta*delta.bias[[n]])\n    \n    #temp<-data.frame(r.weights[[n]])\n    for (ew in 1:4) { \n      rbind(nwn[[n]],do.call(data.frame, l.neurons[[n]][2])[[1]][[ew]]-eta*n.r[[n]][[ew]])\n      #nwn[[n]]<-rbind(do.call(nwn[[n]],unlist(l.neurons[[n]][[2]])))\n    }\n    rbind(gen[[g]],do.call(data.frame,nwn))\n    #rbind(nwn[g],nwn)\n    #shaban[[n]]<-rbind(shaban,nwn)\n  }\n  #rbind(gen[[g]],do.call(data.frame,nwn))\n  #rbind(nwn,do.call(data.frame,nwn))\n}\ndim(nwn)\ndo.call(data.frame,nwn)\ndo.call(data.frame, l.neurons[[1]][2])[[1]][[1]]\nl.neurons[[n]][2][[1]]\nl.neurons[[n]][2]\n\nrbind(nwn[[n]],do.call(data.frame, l.neurons[[n]][2])[[1]])\n \n\nnwn<-list(data.frame(l.neurons[[1]][[2]]),data.frame(l.neurons[[1]][[2]]),data.frame(l.neurons[[1]][[2]]))\nnwn<-data.frame(l.neurons[[1]][[2]],l.neurons[[2]][[2]],l.neurons[[3]][[2]])\nlength(nwn[[2]])\n#l.neurons[[1]][[2]]\ntemp<-data.frame()\nfor (n in 1:3){\n  r.bias[[n]]<-cbind(r.bias[[n]],r.bias[[n]]-eta*delta.bias[[n]])\n\n  #temp<-data.frame(r.weights[[n]])\n  for (ew in 1:4) { \n   # for (i in 1:1){\n   l.neurons[[n]][[2]][[ew]]=l.neurons[[n]][[2]][[ew]]-eta*n.r[[n]][[ew]]\n  temp[[n]]=l.neurons[[n]][[2]][[ew]]\n      #temp[i,ew]<-temp[i,ew]-eta*n.r[[n]][[ew]]\n  #  }\n  }\n  \n  nwn[[n]]<-rbind(do.call(nwn[[n]],unlist(l.neurons[[n]][[2]])))\n}\nnwn[[2]]\nstr(l.neurons[[n]][[2]])\nrbind(nwn[[2]],do.call(data.frame, l.neurons[[1]][2])[[1]])\n\nff[,1]\n\nn=1\ndo.call(data.frame, l.neurons[[1]][2])[[1]]\n#nwn[[n]]<-\nlength(as.vector(nwn  ))\n  rbind(nwn,as.vector(l.neurons[[n]][[2]]))\n\nstr(nwn[[n]])\nstr(l.neurons[[n]][[2]])\nlength\nas.vector(l.neurons[[n]][[2]])\ntemp\nclass(l.neurons[[n]][[2]])\nclass(nwn)\nnwn[[1]]\n",
    "created" : 1498206117184.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1834041235",
    "id" : "8B4A3961",
    "lastKnownWriteTime" : 1498400320,
    "last_content_update" : 1498400320467,
    "path" : "~/machine_learning/multi_layer_neuron/multineuron.R",
    "project_path" : "multineuron.R",
    "properties" : {
        "tempName" : "Untitled6"
    },
    "relative_order" : 1,
    "source_on_save" : true,
    "source_window" : "",
    "type" : "r_source"
}